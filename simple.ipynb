{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'face/face.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Inicjalizacja MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# Inicjalizacja MediaPipe DrawingUtils\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Wczytanie obrazu z pliku jpg\n",
    "image = cv2.imread(test_path)\n",
    "\n",
    "# Przekształcenie obrazu do RGB\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Przetworzenie obrazu za pomocą Face Mesh\n",
    "result = face_mesh.process(rgb_image)\n",
    "\n",
    "# Rysowanie okularów na twarzy\n",
    "if result.multi_face_landmarks:\n",
    "    for face_landmarks in result.multi_face_landmarks:\n",
    "        # Pobranie punktów charakterystycznych dla oczu\n",
    "        left_eye = face_landmarks.landmark[33]\n",
    "        left_eye_l = left_eye\n",
    "        left_eye_p = face_landmarks.landmark[133]\n",
    "        right_eye = face_landmarks.landmark[263]\n",
    "        right_eye_l = right_eye\n",
    "        right_eye_p = face_landmarks.landmark[263]\n",
    "        # Obliczenie pozycji i rozmiaru okularów\n",
    "        glasses_width = int(abs(left_eye.x - right_eye.x) * image.shape[1])\n",
    "        glasses_height = glasses_width // 3\n",
    "\n",
    "        left_eye_cv = (int(abs(left_eye.x) * image.shape[1]) + int(glasses_width /8), int(abs(left_eye.y) * image.shape[0]))\n",
    "        right_eye_cv = ( int(abs(right_eye.x) * image.shape[1]- int(glasses_width /8)), int(abs(right_eye.y) * image.shape[0]) )\n",
    "\n",
    "\n",
    "        # Obliczenie pozycji okularów na obrazie\n",
    "        top_left = (int(min(left_eye.x, right_eye.x) * image.shape[1]), int((left_eye.y + right_eye.y) / 2 * image.shape[0]))\n",
    "        bottom_right = (top_left[0] + glasses_width, top_left[1] + glasses_height)\n",
    "\n",
    "        # Rysowanie okularów na obrazie za pomocą OpenCV\n",
    "        #cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        cv2.circle(image, left_eye_cv, int(glasses_width /4), (0, 255, 0), 2)\n",
    "        cv2.circle(image, right_eye_cv, int(glasses_width /4), (0, 255, 0), 2)\n",
    "\n",
    "# Wyświetlenie obrazu\n",
    "cv2.imshow('MediaPipe FaceMesh with Glasses', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Inicjalizacja MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# Inicjalizacja MediaPipe DrawingUtils\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Wczytanie obrazu z pliku jpg\n",
    "image = cv2.imread(test_path)\n",
    "\n",
    "# Wczytanie obrazu okularów\n",
    "glasses = cv2.imread('okulary.png', -1)\n",
    "\n",
    "# Przekształcenie obrazu do RGB\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Przetworzenie obrazu za pomocą Face Mesh\n",
    "result = face_mesh.process(rgb_image)\n",
    "\n",
    "# Rysowanie okularów na twarzy\n",
    "if result.multi_face_landmarks:\n",
    "    for face_landmarks in result.multi_face_landmarks:\n",
    "        # Pobranie punktów charakterystycznych dla oczu\n",
    "        left_eye = face_landmarks.landmark[33]\n",
    "        right_eye = face_landmarks.landmark[263]\n",
    "\n",
    "        # Obliczenie pozycji i rozmiaru okularów\n",
    "        glasses_width = int(abs(left_eye.x - right_eye.x) * image.shape[1])\n",
    "        glasses_height = glasses_width * glasses.shape[0] // glasses.shape[1]\n",
    "        glasses_resized = cv2.resize(glasses, (glasses_width, glasses_height))\n",
    "\n",
    "        # Obliczenie pozycji okularów na obrazie\n",
    "        top_left = (int(min(left_eye.x, right_eye.x) * image.shape[1]), int((left_eye.y + right_eye.y) / 2 * image.shape[0]))\n",
    "        bottom_right = (top_left[0] + glasses_width, top_left[1] + glasses_height)\n",
    "\n",
    "        # Dodanie okularów do obrazu z uwzględnieniem przezroczystości\n",
    "        alpha_glasses = glasses_resized[:, :, 3] / 255.0\n",
    "        alpha_image = 1.0 - alpha_glasses\n",
    "\n",
    "        for c in range(0, 3):\n",
    "            image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0], c] = (alpha_glasses * glasses_resized[:, :, c] +\n",
    "                alpha_image * image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0], c])\n",
    "\n",
    "# Wyświetlenie obrazu\n",
    "cv2.imshow('MediaPipe FaceMesh with Glasses', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Inicjalizacja MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# Inicjalizacja MediaPipe DrawingUtils\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# Wczytanie obrazu z pliku jpg\n",
    "image = cv2.imread(test_path)\n",
    "\n",
    "# Przekształcenie obrazu do RGB\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Przetworzenie obrazu za pomocą Face Mesh\n",
    "result = face_mesh.process(rgb_image)\n",
    "\n",
    "# Rysowanie punktów charakterystycznych na twarzy\n",
    "if result.multi_face_landmarks:\n",
    "    for face_landmarks in result.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            landmark_drawing_spec=drawing_spec)\n",
    "\n",
    "# Wyświetlenie obrazu\n",
    "cv2.imshow('MediaPipe FaceMesh', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe.python.solutions.face_mesh' has no attribute 'FACE_CONNECTIONS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb Komórka 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mmulti_face_landmarks:\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mfor\u001b[39;00m face_landmarks \u001b[39min\u001b[39;00m result\u001b[39m.\u001b[39mmulti_face_landmarks:\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m             image\u001b[39m=\u001b[39mimage,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m             landmark_list\u001b[39m=\u001b[39mface_landmarks,\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m             connections\u001b[39m=\u001b[39mmp_face_mesh\u001b[39m.\u001b[39;49mFACE_CONNECTIONS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m             landmark_drawing_spec\u001b[39m=\u001b[39mdrawing_spec,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m             connection_drawing_spec\u001b[39m=\u001b[39mdrawing_spec)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Wyświetlenie obrazu\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/mk/3TB/github/SportPlayerPhoto/simple.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mMediaPipe FaceMesh\u001b[39m\u001b[39m'\u001b[39m, image)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mediapipe.python.solutions.face_mesh' has no attribute 'FACE_CONNECTIONS'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Inicjalizacja MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# Inicjalizacja MediaPipe DrawingUtils\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# Wczytanie obrazu z pliku jpg\n",
    "image = cv2.imread('img/Aleksander_Rutkowski_1.jpg')\n",
    "\n",
    "# Przekształcenie obrazu do RGB\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Przetworzenie obrazu za pomocą Face Mesh\n",
    "result = face_mesh.process(rgb_image)\n",
    "\n",
    "# Rysowanie punktów charakterystycznych na twarzy\n",
    "if result.multi_face_landmarks:\n",
    "    for face_landmarks in result.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACE_CONNECTIONS,\n",
    "            landmark_drawing_spec=drawing_spec,\n",
    "            connection_drawing_spec=drawing_spec)\n",
    "\n",
    "# Wyświetlenie obrazu\n",
    "cv2.imshow('MediaPipe FaceMesh', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
